{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWWQKpXq5pa8aIjK4J5NGn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kapilgarg/Robotics/blob/main/YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install ultralytics\n"
      ],
      "metadata": {
        "id": "wbukktHJc0jw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "5066f3a2-cc2a-4bd5-c780-0c58f457f33d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.235-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.235-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.235 ultralytics-thop-2.0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "\n",
        "model = YOLO('yolov8n.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0i0ES52gxXuk",
        "outputId": "5493dc77-afe9-49d4-fb80-07bbab0b207f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 23.3MB/s 0.3s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "\n",
        "# Load pre-trained model\n",
        "model = YOLO('yolov8n.pt')  # Downloads automatically if not present\n",
        "# Options: yolov8n.pt (nano), yolov8s.pt (small), yolov8m.pt (medium),\n",
        "#          yolov8l.pt (large), yolov8x.pt (xlarge)\n",
        "\n",
        "# ===== METHOD 1: Single Image =====\n",
        "def detect_image(image_path):\n",
        "    # Run inference\n",
        "    results = model(image_path)\n",
        "\n",
        "    # Process results\n",
        "    for result in results:\n",
        "        boxes = result.boxes  # Bounding boxes\n",
        "        for box in boxes:\n",
        "            # Get box coordinates\n",
        "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "\n",
        "            # Get confidence and class\n",
        "            conf = float(box.conf[0])\n",
        "            cls = int(box.cls[0])\n",
        "            class_name = model.names[cls]\n",
        "\n",
        "            print(f\"Detected: {class_name}, Confidence: {conf:.2f}\")\n",
        "            print(f\"Box: ({x1:.0f}, {y1:.0f}), ({x2:.0f}, {y2:.0f})\")\n",
        "\n",
        "    # Show annotated image\n",
        "    # annotated_frame = results[0].plot()\n",
        "    # cv2.imshow('YOLOv8 Detection', annotated_frame)\n",
        "    # cv2.waitKey(0)\n",
        "    # cv2.destroyAllWindows()\n",
        "\n",
        "# ===== METHOD 2: Webcam/Video Stream =====\n",
        "def detect_webcam():\n",
        "    cap = cv2.VideoCapture(0)  # 0 for default webcam\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Run inference on frame\n",
        "        results = model(frame, verbose=False)  # verbose=False to reduce print output\n",
        "\n",
        "        # Get annotated frame\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        # Display\n",
        "        cv2.imshow('YOLOv8 Webcam', annotated_frame)\n",
        "\n",
        "        # Press 'q' to quit\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# ===== METHOD 3: Video File =====\n",
        "def detect_video(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        results = model(frame)\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        cv2.imshow('YOLOv8 Video', annotated_frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# ===== METHOD 4: With Action Based on Detection =====\n",
        "def detect_and_act(image_path):\n",
        "    results = model(image_path, conf=0.5)  # confidence threshold\n",
        "\n",
        "    for result in results:\n",
        "        boxes = result.boxes\n",
        "        for box in boxes:\n",
        "            cls = int(box.cls[0])\n",
        "            conf = float(box.conf[0])\n",
        "            class_name = model.names[cls]\n",
        "\n",
        "            # Take action based on detected object\n",
        "            if class_name == 'person':\n",
        "                print(\"Person detected! Taking action...\")\n",
        "                # Your robot action here\n",
        "            elif class_name == 'bottle':\n",
        "                print(\"Bottle detected! Picking up...\")\n",
        "                # Your robot action here\n",
        "            elif class_name == 'cup':\n",
        "                print(\"Cup detected!\")\n",
        "                # Your robot action here\n",
        "\n",
        "# ===== METHOD 5: Save Results =====\n",
        "def detect_and_save(image_path, output_path):\n",
        "    results = model(image_path)\n",
        "\n",
        "    # Save annotated image\n",
        "    annotated_frame = results[0].plot()\n",
        "    cv2.imwrite(output_path, annotated_frame)\n",
        "    print(f\"Saved result to {output_path}\")\n",
        "\n",
        "# ===== METHOD 6: Get Detailed Information =====\n",
        "def detect_detailed(image_path):\n",
        "    results = model(image_path)\n",
        "\n",
        "    for result in results:\n",
        "        # Get image dimensions\n",
        "        img_height, img_width = result.orig_shape\n",
        "\n",
        "        boxes = result.boxes\n",
        "        print(f\"Found {len(boxes)} objects\")\n",
        "\n",
        "        for i, box in enumerate(boxes):\n",
        "            # Bounding box coordinates (normalized 0-1)\n",
        "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "\n",
        "            # Convert to pixel coordinates\n",
        "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "\n",
        "            # Box dimensions\n",
        "            width = x2 - x1\n",
        "            height = y2 - y1\n",
        "\n",
        "            # Center point\n",
        "            center_x = (x1 + x2) // 2\n",
        "            center_y = (y1 + y2) // 2\n",
        "\n",
        "            conf = float(box.conf[0])\n",
        "            cls = int(box.cls[0])\n",
        "            class_name = model.names[cls]\n",
        "\n",
        "            print(f\"\\nObject {i+1}:\")\n",
        "            print(f\"  Class: {class_name}\")\n",
        "            print(f\"  Confidence: {conf:.2%}\")\n",
        "            print(f\"  Bounding Box: ({x1}, {y1}) to ({x2}, {y2})\")\n",
        "            print(f\"  Size: {width}x{height} pixels\")\n",
        "            print(f\"  Center: ({center_x}, {center_y})\")\n",
        "\n",
        "# ===== Main Execution =====\n",
        "if __name__ == \"__main__\":\n",
        "    # Uncomment the one you want to run:\n",
        "\n",
        "    #detect_image('/content/workspace (4).webp')\n",
        "    detect_webcam()\n",
        "    # detect_video('path/to/video.mp4')\n",
        "    # detect_and_act('path/to/image.jpg')\n",
        "    # detect_and_save('input.jpg', 'output.jpg')\n",
        "    # detect_detailed('path/to/image.jpg')"
      ],
      "metadata": {
        "id": "lVFdbqlEy1hC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O-DKLXeSxhNE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}